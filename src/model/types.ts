/* eslint-disable no-use-before-define */
import {
  type AIChatClient,
  type AICompletionClient,
  type AIEmbeddingClient,
  type ChatParams,
  type ChatResponse,
  type ChatStreamResponse,
  type CompletionParams,
  type CompletionResponse,
  type EmbeddingParams,
  type EmbeddingResponse,
} from 'ai-fetch';
import { type Options as KYOptions } from 'ky';

import { type ChatModel } from './chat.js';
import { type CompletionModel } from './completion.js';
import { type EmbeddingModel } from './embedding.js';
import { type AbstractModel } from './model.js';
import { type SparseVectorModel } from './sparse-vector.js';

type InnerType<T> = T extends ReadableStream<infer U> ? U : never;

/** All possible message types except Refusal, which we throw errors for instead. */
export type Msg =
  | Msg.System
  | Msg.User
  | Msg.Assistant
  | Msg.Refusal
  | Msg.FuncCall
  | Msg.FuncResult
  | Msg.ToolCall
  | Msg.ToolResult;

export namespace Msg {
  export namespace Call {
    /** The name and arguments of a function that should be called, as generated by the model. */
    export type Function = {
      /** The arguments to call the function with, as generated by the model in JSON format. */
      arguments: string;
      /** The name of the function to call. */
      name: string;
    };

    /** The tool calls generated by the model, such as function calls. */
    export type Tool = {
      /** The ID of the tool call. */
      id: string;
      /** The type of the tool. Currently, only `function` is supported. */
      type: 'function';
      /** The function that the model called. */
      function: Call.Function;
    };
  }

  /** Message with text content for the system. */
  export type System = {
    role: 'system';
    content: string;
    name?: string;
  };

  /** Message with text content from the user. */
  export type User = {
    role: 'user';
    name?: string;
    content: string;
  };

  /** Message with text content from the assistant. */
  export type Assistant = {
    role: 'assistant';
    name?: string;
    content: string;
  };

  /** Message with a refusal reason and no content. */
  export type Refusal = {
    role: 'assistant';
    refusal: string;
    content?: null;
  };

  /** Message with arguments to call a function. */
  export type FuncCall = {
    role: 'assistant';
    name?: string;
    content: null;
    function_call: Call.Function;
  };

  /** Message with the result of a function call. */
  export type FuncResult = {
    role: 'function';
    name: string;
    content: string;
  };

  /** Message with arguments to call one or more tools. */
  export type ToolCall = {
    role: 'assistant';
    name?: string;
    content: null;
    tool_calls: Call.Tool[];
  };

  /** Message with the result of a tool call. */
  export type ToolResult = {
    role: 'tool';
    tool_call_id: string;
    content: string;
  };
}

/**
 * Generic Model extended by provider specific implementations.
 */
export namespace Model {
  /**
   * Base model
   */
  export namespace Base {
    /** Client for making API calls. Extended by specific model clients. */
    export type Client = any;

    export type AvailableModels<C> = C extends Client
      ? {
          [K in keyof C]: C[K] extends (params: infer P) => any
            ? P extends { model: infer M }
              ? M
              : never
            : never;
        }[keyof C]
      : never;

    export interface Config<C extends Client> {
      model: AvailableModels<C>;
    }
    export interface Run {
      [key: string]: any;
      requestOpts?: {
        signal?: AbortSignal;
        headers?: KYOptions['headers'];
      };
    }
    export interface Params<C extends Client> extends Config<C>, Run {}
    export interface Response {
      cached: boolean;
      latency?: number;
      cost?: number;
    }
    export type Model = AbstractModel<
      Client,
      Config<Client>,
      Run,
      Response,
      any
    >;
  }

  /**
   * Chat Model
   */
  export namespace Chat {
    export type Client = AIChatClient;

    type AvailableModels<C> = C extends Client
      ? C extends { createChatCompletion: (params: infer P) => any }
        ? P extends { model: infer M }
          ? M
          : never
        : never
      : never;

    type Params<C extends Client> = ChatParams<AvailableModels<C>>;

    export interface Run extends Base.Run {
      messages: Msg[];
      handleUpdate?: (chunk: string) => void;
    }
    export interface Config<C extends Client> extends Base.Config<C> {
      /** Handle new chunk from streaming requests. */
      handleUpdate?: (chunk: string) => void;
      frequency_penalty?: Params<C>['frequency_penalty'];
      function_call?: Params<C>['function_call'];
      functions?: Params<C>['functions'];
      logit_bias?: Params<C>['logit_bias'];
      max_tokens?: Params<C>['max_tokens'];
      model: Params<C>['model'];
      presence_penalty?: Params<C>['presence_penalty'];
      response_format?: Params<C>['response_format'];
      seed?: Params<C>['seed'];
      stop?: Params<C>['stop'];
      temperature?: Params<C>['temperature'];
      tools?: Params<C>['tools'];
      tool_choice?: Params<C>['tool_choice'];
      top_p?: Params<C>['top_p'];
    }
    export interface Response extends Base.Response, ChatResponse {
      message: Msg;
    }
    /** Streaming response from the OpenAI API. */
    type StreamResponse = ChatStreamResponse;
    /** A chunk recieved from a streaming response */
    export type CompletionChunk = InnerType<StreamResponse>;
    export type ApiResponse = ChatResponse;
    export type Model = ChatModel<Ctx, Client, Config<Client>>;
  }

  /**
   * Completion model
   */
  export namespace Completion {
    export type Client = AICompletionClient;

    type AvailableModels<C> = C extends Client
      ? C extends { createCompletion: (params: infer P) => any }
        ? P extends { model: infer M }
          ? M
          : never
        : never
      : never;

    type Params<C> = CompletionParams<AvailableModels<C>>;

    export interface Run extends Base.Run {
      prompt: string | string[] | number[] | number[][] | null;
    }
    export interface Config<C extends Client>
      extends Base.Config<C>,
        Omit<Params<C>, 'prompt' | 'user'> {
      model: Params<C>['model'];
    }
    export interface Response extends Base.Response, CompletionResponse {
      completion: string;
    }
    export type ApiResponse = CompletionResponse;
    export type Model = CompletionModel;
  }

  /** Generic metadata object. */
  export type Ctx = { [key: string]: any };

  /**
   * Embedding Model
   */
  export namespace Embedding {
    export type Client = AIEmbeddingClient;

    type AvailableModels<C> = C extends Client
      ? C extends { createEmbeddings: (params: infer P) => any }
        ? P extends { model: infer M }
          ? M
          : never
        : never
      : never;

    type Params<C> = EmbeddingParams<AvailableModels<C>>;

    export interface Run extends Base.Run {
      input: string[];
    }
    /** API request batching options */
    export interface BatchOptions {
      maxTokensPerBatch: number;
      maxBatchSize: number;
    }
    /** API request throttling options */
    interface ThrottleOptions {
      maxRequestsPerMin: number;
      maxConcurrentRequests: number;
    }
    export interface Config<C extends Client>
      extends Base.Config<C>,
        Omit<Params<C>, 'input' | 'user'> {
      model: Params<C>['model'];
      batch?: Partial<BatchOptions>;
      throttle?: Partial<ThrottleOptions>;
    }
    export interface Response extends Base.Response, EmbeddingResponse {
      embeddings: number[][];
    }
    export type ApiResponse = EmbeddingResponse;
    export type Model = EmbeddingModel;
  }

  /**
   * Event handlers for logging and debugging
   */
  export interface Events<
    C extends Model.Base.Client,
    MParams extends Model.Base.Params<C>,
    MResponse extends Model.Base.Response,
    MCtx extends Model.Ctx,
    AResponse = any,
  > {
    onStart?: ((event: {
      timestamp: string;
      modelType: Type;
      modelProvider: Provider;
      params: Readonly<Model.Base.Run & Partial<Model.Base.Config<C>>>;
      context: Readonly<MCtx>;
    }) => void | Promise<void>)[];
    onApiResponse?: (<P extends Model.Base.Params<C>>(event: {
      timestamp: string;
      modelType: Type;
      modelProvider: Provider;
      params: Readonly<P>;
      response: Readonly<AResponse>;
      latency: number;
      context: Readonly<MCtx>;
    }) => void | Promise<void>)[];
    onComplete?: ((event: {
      timestamp: string;
      modelType: Type;
      modelProvider: Provider;
      params: Readonly<MParams>;
      response: Readonly<MResponse>;
      context: Readonly<MCtx>;
      cached: boolean;
    }) => void | Promise<void>)[];
    onError?: ((event: {
      timestamp: string;
      modelType: Type;
      modelProvider: Provider;
      params: Readonly<MParams>;
      error: unknown;
      context: Readonly<MCtx>;
    }) => void | Promise<void>)[];
  }

  /**
   * Generic interface for a model tokenizer
   */
  export interface ITokenizer {
    /** Tokenize a string into an array of integer tokens */
    encode(text: string): Uint32Array;
    /** Decode an array of integer tokens into a string */
    decode(tokens: number[] | Uint32Array): string;
    /**
     * Count the number of tokens in a string or message(s).
     * A single Msg is counted as a completion and an array as a prompt.
     * Strings are counted as is.
     */
    countTokens(input?: string | Msg | Msg[]): number;
    /** Truncate a string to a maximum number of tokens */
    truncate(args: {
      /** Text to truncate */
      text: string;
      /** Maximum number of tokens to keep (inclusive) */
      max: number;
      /** Truncate from the start or end of the text */
      from?: 'start' | 'end';
    }): string;
  }

  /** The provider of the model (eg: OpenAI) */
  export type Provider = (string & {}) | 'openai' | 'custom';

  /**
   * Sparse vector model (SPLADE)
   */
  export namespace SparseVector {
    export type Client = {
      createSparseVector: (
        params: {
          input: string;
          model: string;
          requestOpts?: {
            headers?: KYOptions['headers'];
          };
        },
        serviceUrl: string
      ) => Promise<SparseVector.Vector>;
    };
    /** Sparse vector from SPLADE models. */
    export type Vector = {
      indices: number[];
      values: number[];
    };
    export interface Run extends Model.Base.Run {
      input: string[];
    }
    export interface Config<C extends Client> extends Model.Base.Config<C> {
      concurrency?: number;
      throttleLimit?: number;
      throttleInterval?: number;
    }
    export interface Response extends Model.Base.Response {
      vectors: Vector[];
    }
    export type ApiResponse = Vector;
    export type Model = SparseVectorModel;
  }

  /** The type of data returned by the model */
  export type Type =
    | (string & {})
    | 'base'
    | 'completion'
    | 'chat'
    | 'embedding'
    | 'sparse-vector';
}
